% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  8pt]{extarticle}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% --- Preamble for Cheatsheet ---
\usepackage[a4paper, landscape, margin=0.5cm]{geometry} % 设置 A4 横向，边距 1cm
\usepackage{amsmath}          % 数学公式增强
\usepackage{amssymb}          % 数学符号 (如 \mathbb)
\usepackage{graphicx}         % 支持插入图片
\usepackage{multicol}         % 支持多栏排版
\setlength{\columnsep}{1em}    % 设置栏间距
\usepackage{parskip}          % 使用段落间距代替首行缩进，更紧凑
\setlength{\parskip}{0.5em plus 0.1em minus 0.1em}
\setlength{\parindent}{0pt}
\usepackage{ctex}             % ctex 中文支持

% 可选：如果默认字体不满意，可以取消注释并指定字体
% \setmainfont{Noto Serif CJK SC}
% \setsansfont{Noto Sans CJK SC}
% \setmonofont{Noto Sans Mono CJK SC}

\setcounter{secnumdepth}{2}    % 可选：控制章节编号深度，Cheatsheet 可能不需要太深
% --- End Preamble ---
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}

\begin{multicols*}{4}
    \footnotesize

    \begin{center}
        \textbf{EAI Cheatsheet} by 卓致用，杨涛瑜，张煦恒
    \end{center}
    \vspace{-1.75em} % 减少标题与内容的间距

\hypertarget{robotics}{%
\section{Robotics}\label{robotics}}

\textbf{Revolute 旋转}，1D；\textbf{Prismatic 滑动}，1D；\textbf{Helical
螺旋}（旋转平移固定比例），1D；\textbf{Spherical
球形}，3D；\textbf{Cartesian space 笛卡尔空间}

\textbf{FK}：正向运动学，给定关节角度，计算末端执行器的位置和姿态。\textbf{IK}：给定正向运动学
\(T_{s \rightarrow e}(\theta)\) 和目标姿态
\(T_{target} = \mathbb{SE}(3)\)，求解满足以下条件的关节角度 \(\theta\)：
\(T_{s \rightarrow e}(\theta) = T_{target}\)。IK 比 FK 更复杂，因为
\(T^{-1}\) 可能很难计算，所以 \textbf{通常可能多解或无解}。

三维空间中 IK 有解需要至少有
6DoF（但有时候只能得到数值解）。\emph{引理：如果机械臂构型满足 Pieper
Criterion，则有解析解（闭式解）}。6DoF
保证有解，但是这个解可能超出了可行空间（如碰撞解），所以额外增加 1
冗余形成 7
DoF，可扩大解空间，更有可能找到可行解。但一味增加自由度会带来工程复杂性并延长反应时间。目前工业界一般
6 或者 7 DoF。

\textbf{欧拉角}：\(R_{x}(\alpha):=\begin{bmatrix}1&0&0\\0&\cos\alpha&-\sin\alpha\\0&\sin\alpha&\cos\alpha\end{bmatrix}, R_{y}(\beta):=\begin{bmatrix}\cos\beta&0&\sin\beta\\0&1&0\\-\sin\beta&0&\cos\beta\end{bmatrix}, R_{z}(\gamma):=\begin{bmatrix}\cos\gamma&-\sin\gamma&0\\\sin\gamma&\cos\gamma&0\\0&0&1\end{bmatrix}\)

任意旋转均可拆为 \(R=R_{z}(\alpha)R_{y}(\beta)R_{x}(\gamma)\)。问题：1.
对于一个旋转矩阵，\textbf{其欧拉角可能不唯一}。2. \textbf{Gimbal
Lock}：如果三次旋转中第二次旋转 \(\beta\) 的角度为 \(\pi/2\)，那么剩下 2
个自由度会变成 1 个。

\textbf{欧拉定理/axis-angle}：任意三维空间中的旋转都可以表示为绕一个固定轴
\(\hat{\omega} \in \mathbb{R}^3\)（单位向量，满足
\(\|\hat{\omega}\| = 1\)）旋转一个正角度 \(\theta\)
的结果。问题：\textbf{不唯一性}：\((\hat{\omega}, \theta)\) 和
\((-\hat{\omega}, 2\pi -\theta)\) 代表同一个旋转；\(\theta=0\) 时对应
\(R=I\)，任意 \(\hat{\omega}\) 都行；\(\theta = \pi\) 时，绕轴
\(\hat{\omega}\) 和绕轴 \(-\hat{\omega}\) 旋转 \(\pi\)
得到的结果是相同的。这种情况对应 \(\text{tr}(R) = -1\)。将旋转角
\(\theta\) 限制在 \((0, \pi)\)
内，那么对于大部分旋转，其轴角表示就是唯一的（不考虑不旋转、旋转
\(\pi\)）。

对于一个单位轴向量（axis）\(\mathbf{u} = [x, y, z]^\top\)，其对应的叉乘矩阵（cross
product
matrix）\(K = \begin{bmatrix}0 & -z & y \\z & 0 & -x \\-y & x & 0\end{bmatrix}\)
是 skew-symmetric
反对称矩阵，\(K\mathbf{v} = \mathbf{u} \times \mathbf{v}\)

\textbf{Rodrigues 旋转公式（向量形式）}：向量 \(\mathbf{v}\)
沿着单位向量 \(\mathbf{u}\) 旋转 \(\theta\) 角度之后的向量
\(\mathbf{v}'\) 为
\(\mathbf{v}' = \cos(\theta)\mathbf{v} + (1 - \cos(\theta))(\mathbf{u} \cdot \mathbf{v})\mathbf{u} + \sin(\theta)(\mathbf{u} \times \mathbf{v})\)
\textbf{（矩阵形式）} 绕单位轴 \(\mathbf{u}\) 旋转 \(\theta\) 的旋转矩阵
\(R_\theta\) 可以表示为
\(R_\theta = I + (1-\cos\theta) K^2 + \sin\theta \cdot K = e^{\theta K}\)。\emph{证明}：拆开级数然后用
\(K^2 = \mathbf{u}\mathbf{u}^\top - I,K^3=-K\)

\textbf{从旋转矩阵 \(R\) 反求 \((\hat{\omega}, \theta)\)}：当
\(\theta \in (0, \pi)\)
时，\(\theta = \arccos \frac{1}{2}[\text{tr}(R) - 1]\)，\([\hat{\omega}] = \frac{1}{2 \sin \theta}(R - R^\top)\)。定义两个旋转矩阵之间的
\textbf{旋转距离}：从姿态 \(R_1\) 转到姿态 \(R_2\)
所需的最小旋转角度。两个旋转的关系是：\((R_2 R_1^\top) R_1 = R_2\)。旋转距离：\(\text{dist}(R_1, R_2) = \theta(R_2 R_1^\top) = \arccos\left(\frac{1}{2} \big[\text{tr}(R_2 R_1^\top) - 1\big]\right)\)

\textbf{Quaternion}：\(q = w + xi + yj + zk\)。其中 \(w\)
实部，\(x,y,z\) 虚部。\(i, j, k\) 是虚数单位，满足
\(i^2 = j^2 = k^2 = ijk = -1\)
和反交换性质（anti-commutative）：\(ij = k = -ji, \quad jk = i = -kj, \quad ki = j = -ik\)。可以表示为向量形式
\(q = (w, \bold{v}), \quad \bold{v} = (x, y, z)\)。

\textbf{乘法}：\(q_1 q_2 = (w_1 w_2 - \bold{v}_1^{\top} \bold{v}_2, \, w_1 \bold{v}_2 + w_2 \bold{v}_1 + \bold{v}_1 \times \bold{v}_2) = (w_1 w_2 - \bold{v}_1 \cdot \bold{v}_2, \, w_1 \bold{v}_2 + w_2 \bold{v}_1 + \bold{v}_1 \times \bold{v}_2)\)；\textbf{不可交换}：
\(q_1 q_2 \neq q_2 q_1\)。\textbf{共轭}：\(q^* = (w, -\bold{v})\)；\textbf{模长}：\(\|q\|^2 = w^2 + \bold{v}^{\top} \bold{v} = qq^* = q^*q\)；\textbf{逆}：\(q^{-1} = \frac{q^*}{\|q\|^2}\)

\textbf{单位四元数}
\(\|q\| = 1\)，可表示三维空间中的旋转，\(q^{-1} = q^*\)。

\textbf{旋转表示}：绕某个单位向量 \(\hat{\omega}\) 旋转 \(\theta\)
角度，对应的四元数：\(q = \left[\cos\frac{\theta}{2}, \sin\frac{\theta}{2} \hat{\omega}\right]\)、
\textbf{双重覆盖}：\(q\) 和 \(-q\) 代表同一个旋转。

\textbf{从四元数恢复轴角表示}：\(\theta = 2 \arccos(w), \quad \hat{\omega} =\begin{cases}\frac{\bold{v}}{\sin(\theta/2)}, & \theta \neq 0 \\0, & \theta = 0\end{cases}\)

\textbf{向量旋转}：任意向量 \(\mathbf{v}\)
沿着以\textbf{单位向量}定义的旋转轴 \(\mathbf{u}\) 旋转 \(\theta\)
度得到 \(\mathbf{v}'\)，那么：令向量 \(\mathbf{v}\) 的四元数形式
\(v = [0, \mathbf{v}]\)，旋转四元数
\(q = \left[\cos\left(\frac{\theta}{2}\right), \sin\left(\frac{\theta}{2}\right)\mathbf{u}\right]\)，则旋转后的向量
\(\mathbf{v}'\) 可表示为：\(\mathbf{v}' = qv q^* = qv q^{-1}\)。

如果是给定四元数 \(q\) 旋转向量 \(\mathbf{v}\) ，那么设
\(q = [w, \mathbf{r}]\) 是单位四元数（即
\(w^2 + \|\mathbf{r}\|^2 = 1\)），向量 \(\mathbf{v}\) 的四元数形式为
\(v = [0, \mathbf{v}]\)。

\emph{证明}：倒三角函数，利用叉乘展开式：\(a \times b \times c = (a \cdot c)b - (a \cdot b)c\)
和 \(w^2 + \|\mathbf{r}\|^2 = 1\) 即可。

\textbf{旋转组合}：两个旋转 \(q_1\) 和 \(q_2\)
的组合等价于四元数的乘法：\(q_2 (q_1 x q_1^*) q_2^* = (q_2 q_1) x (q_1^* q_2^*)\)，不满足交换律，满足结合律。

令单位四元数
\(q = w + x\mathbf{i} + y\mathbf{j} + z\mathbf{k} = [w, (x, y, z)]\)，则旋转矩阵
\(R(q)\) 为
\(R(q) = \begin{bmatrix} 1 - 2y^2 - 2z^2 & 2xy - 2zw & 2xz + 2yw \\ 2xy + 2zw & 1 - 2x^2 - 2z^2 & 2yz - 2xw \\ 2xz - 2yw & 2yz + 2xw & 1 - 2x^2 - 2y^2 \end{bmatrix}\)。由此，\(\text{tr}(R) = 3 - 4(x^2 + y^2 + z^2) = 4w^2 - 1\)，所以：\(w = \frac{\sqrt{\text{tr}(R)+1}}{2}，x = \frac{R_{32}-R_{23}}{4w}，y = \frac{R_{13}-R_{31}}{4w}，z = \frac{R_{21}-R_{12}}{4w}\)。其中
\(R_{ij}\) 表示矩阵 \(R\) 的第 \(i\) 行第 \(j\) 列的元素。这些公式在
\(w \neq 0\) 时有效。

在单位三维球面 \(S^3\) 上，或两个四元数 \((q_1, q_2)\) 之间的角度
\(\langle p, q \rangle = \arccos(p \cdot q)\)。\emph{证明}：设
\(p = (p_w, \mathbf{p}_v)\) 和 \(q = (q_w, \mathbf{q}_v)\)，那么显然，从
\(p\) 旋转到 \(q\) 的相对旋转可以由四元数乘法 \(\Delta q = q p^*\)
表示。\(\Delta q = (q_w p_w + \mathbf{q}_v \cdot \mathbf{p}_v, \dots)\)
的实部是 \(p \cdot q\)。对应到旋转的距离就是乘个
\(2\)：\(\text{dist}(p, q) = 2 \min \{\langle p, q \rangle, \langle p, -q \rangle\}\)。\textbf{要两个取最小值是因为双倍覆盖。}两个旋转
\((R_1, R_2)\) 的距离与其对应四元数 \(q(R_1)\) 和 \(q(R_2)\)
在球面上的距离成线性关系（前者是后者的两倍）。

\textbf{线性插值（Lerp）}：\(q(t) = (1-t)q_1 + tq_2\)。\textbf{归一化线性插值（Nlerp）}：\(q(t) = \frac{(1-t)q_1 + tq_2}{\|(1-t)q_1 + tq_2\|}\)（除个模长恢复为单位四元数）。以上两种插值都有问题，他们实际上是线性切分了弦长而不是弧长，会导致在转动时角速度不均匀。\textbf{球面线性插值（Slerp）}：\(q(t) = \frac{\sin((1-t)\theta)}{\sin(\theta)} q_1 + \frac{\sin(t\theta)}{\sin(\theta)} q_2\)，其中
\(\theta\) 是 \(q_1\) 和 \(q_2\)
之间的夹角，\(\theta = \arccos(q_1 \cdot q_2)\)。\emph{证明}：正弦定理。

\textbf{球面均匀采样：}：在 \(\mathbb{SO}(3)\)
中均匀采样旋转矩阵等价于从单位四元数的集合 \(\mathbb{S}(3)\)
中均匀采样。原因：两个旋转之间的距离与对应的四元数在单位球面上的距离成线性关系。均匀采样
\(\mathbb{S}(3)\)：从\textbf{四维标准正态分布}
\(\mathcal{N}(0, I_{4 \times 4})\)
中随机采样一个变量，将其归一化。原因：由于标准正态分布是各向同性的，所以采样得到的单位四元数在
\(\mathbb{SO}(3)\) 中也是均匀分布的。

\begin{itemize}
\tightlist
\item
  \textbf{旋转矩阵}：可逆、可组合（矩阵连乘）、但在 \(\mathbb{SO}(3)\)
  上移动不直接，\textbf{但最适合作为 NN 输出：连续性}。
\item
  \textbf{欧拉角}：逆向复杂、组合复杂、因为 Gimbal lock 的存在，与
  \(\mathbb{SO}(3)\) 不能平滑映射
\item
  \textbf{轴角}：可逆、组合复杂、大部分情况下可以与 \(\mathbb{SO}(3)\)
  平滑映射，但是在边界情况（如旋转 \(0\) 度时）不行
\item
  \textbf{四元数}：可逆，可组合，平滑映射，但存在双倍覆盖的问题
\end{itemize}

碰撞检测：\textbf{球体包裹法 Bounding
Spheres}，缺点：\textbf{保守性导致可行解丢失}，限制了模型对于更精细物体的操作能力（很小的面片，虚假自碰撞）；\textbf{凸分解
Convex Decomposition}，精确分解 NP hard 不实用，近似 ACD 常用。

运动规划：\textbf{PRM 算法}：在 \(C_{\text{free}}\) 中随机
sample（不重），然后连接 \(k\)
近邻，剔除碰撞边（这一步用连线上线性采样来处理），然后用搜索或者 Dij
找路。\textbf{场景不变时可复用}。\textbf{高斯采样}：先随机
\(q_1\)，\(\mathcal N (q_1, \sigma^2)\) 生成 \(q_2\)，如果
\(q_1 \in C_{\text{free}}\) 且 \(q_2 \notin C_{\text{free}}\)，则添加
\(q_1\)。\textbf{有边界偏好，效率低}。\textbf{桥采样}：计算中点
\(q_3\)，当 \(q_1,q_2\) 都寄才要 \(q_3\)。\textbf{PRM 具有渐进最优性
asymptotically-optimal}

\textbf{RRT}：exploration（随机采样）and exploitation（向着 goal
走）。探索参数 \(\beta\)、步长 \(\epsilon\) 和采样点数量 \(n\)
都要调。\textbf{RRT-Connect}：双向
RRT、定向生长策略（扩展目标选择最近的另一树的叶子）、多种步长贪婪扩展。\textbf{Shortcutting}：平滑路径。可以多次
RRT 后并行 shortcutting。\textbf{RRT 和 RRT-Connect 不是渐近最优的。}

\textbf{控制系统的性能评价}：最小化稳态（Steady-State）误差；最小化调节时间，快速达到稳态；最小化稳态附近的振荡。\textbf{FeadForward
开环控制}：规划完闭眼做事无反馈纠错；\textbf{FeadBack
闭环控制}：带反馈回路，稳定。

期望状态：\(\theta_d\)（destination），当前状态：\(\theta\)，误差：\(\theta_e = \theta_d - \theta\)。

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{稳态误差（Steady-State Error）}：系统到达稳态后的残余误差
  \(e_{ss} = \lim_{t\to\infty} \theta_e(t)\)。理想系统应满足
  \(e_{ss}=0\)
\item
  \textbf{调节时间（Settling Time）}：误差首次进入并保持在 \(\pm 2\%\)
  误差带所需时间，transient response 瞬态响应
\item
  \textbf{超调量（Overshoot）}：系统响应超过稳态值的程度，最开始过去不算
  \(\text{overshoot} = |a/b| \times 100\%\)，其中，\(a\)
  表示最大偏移量，\(b\) 表示最终稳态值
\end{enumerate}

\textbf{P 控制
Proportional}：\(P = K_p\theta_e(t)\)。\textbf{一阶形式}：当控制信号改变状态的导数（即控制速度信号）时：\(\dot{\theta}(t) = P = K_p\theta_e(t)\)，若希望状态以
\(\dot{\theta}_d(t) = c\) 移动，则
\(\dot{\theta}_e(t) + K_p\theta_e(t) = c\)，解 ODE 得到
\(\theta_e(t) = \frac{c}{K_p} + \left(\theta_e(0) - \frac{c}{K_p}\right)e^{-K_pt}\)。当
\(c\neq0\)（目标移动）时：随着
\(t\rightarrow\infty\)，\(e^{-K_pt}\rightarrow0\)稳态误差：\(\lim_{t\rightarrow\infty}\theta_e(t) = \frac{c}{K_p}\)。\textbf{系统存在永久稳态误差}，误差大小与目标速度
\(c\) 成正比，与比例增益 \(K_p\) 成反比，增大 \(K_p\)
可以减小稳态误差。\textbf{二阶形式}：控制信号改变状态的二阶导数（力或力矩信号）：\(\ddot{\theta}(t) = P = K_p\theta_e(t)\)，导致状态振荡且不稳定。

\textbf{PI 控制
Integral}：\(PI = K_p \theta_e(t) + K_i \int_0^t \theta_e(\tau) \mathrm{d}\tau\)。如果控制信号作用于状态导数（速度）：\(\dot{\theta}(t) = PI = K_p \theta_e(t) + K_i \int_0^t \theta_e(\tau) \mathrm{d}\tau\)，\(\dot{\theta}_e(t) = \dot{\theta}_d(t) - \dot{\theta}(t)\)，\(\dot{\theta}_d(t) = \dot{\theta}_e(t) + \dot{\theta}(t)\)，两边求导：\(\ddot{\theta}_d(t) = \ddot{\theta}_e(t) + K_p \dot{\theta}_e(t) + K_i \theta_e(t)\)，如果
\(\ddot{\theta}_d(t) = 0\)（目标加速度为零），\(\ddot{\theta}_e(t) + K_p \dot{\theta}_e(t) + K_i \theta_e(t) = 0\)，为二阶常系数齐次微分方程。解的形式由方程特征根决定，特征方程为：\(r^2 + K_p r + K_i = 0\)。

其解的形式决定系统的阻尼特性：\textbf{过阻尼
(Overdamped)}：两个实根，系统缓慢收敛。\textbf{临界阻尼 (Critically
damped)}：双重实根，快速无振荡收敛。\textbf{欠阻尼
(Underdamped)}：共轭复根，系统振荡收敛。

\textbf{PD 控制
Derivative}：\(PD = K_p \theta_e(t) + K_d \frac{\mathrm{d}}{\mathrm{d}t}\theta_e(t)\)。如果
\(\ddot{\theta}_d(t) = 0\)（目标加速度为零），则
\(\ddot{\theta}_e(t) + K_d \dot{\theta}_e(t) + K_p \theta_e(t) = 0\)，解的形式由方程特征根决定，特征方程为：\(r^2 + K_d r + K_p = 0\)。

\textbf{PID
控制}：\(PID = K_p \theta_e(t) + K_i \int_0^t \theta_e(\tau)\mathrm{d}\tau + K_d \frac{\mathrm{d}}{\mathrm{d}t}\theta_e(t)\)。

\textbf{\(K_p\) 控制当前状态}：\(K_p\) 增大可 \textbf{加快响应速度（Rise
Time）}、减少调节时间，因为快速减少
\(\theta_e(t)\)；\textbf{增大超调量}；\textbf{单用会产生稳态误差}。

\textbf{\(K_i\)
控制历史累积}：对持续误差进行累积补偿，\textbf{消除稳态误差}；\textbf{增大超调量}。

\textbf{\(K_d\)
预测未来趋势}：减少调节时间，\textbf{抑制超调和振荡}；当误差增加时提供更强的控制作用；当误差减小时提供更温和的控制作用。

\hypertarget{vision-and-grasping}{%
\section{Vision-and-Grasping}\label{vision-and-grasping}}

\textbf{抓握式操作} （Prehensile
Manipulation）：通过完全约束物体自由度实现精确控制。\textbf{非抓握式操作}：利用推、滑等接触力学原理调整物体状态，适用于薄片状物体或预处理场景，\textbf{不是所有动作都需要抓取}

\textbf{抓取姿势（Grasp Pose）}：手的位置、方向和关节状态 \&
\textbf{抓取的自由度}

\begin{itemize}
\tightlist
\item
  \textbf{4-DoF 抓取}：仅需平移和绕重力轴旋转 \((x, y, z, \theta_z)\)
\item
  \textbf{6-DoF 抓取}：允许任意方向接近
  \((x, y, z, \theta_x, \theta_y, \theta_z)\)
\item
  \textbf{手指自由度}：平行夹爪：开 / 关，1 DoF；灵巧手（Dexterous
  Hand）：21 DoF
\end{itemize}

\textbf{开环抓取系统}：一般处理流程包括视觉感知、位姿估计、运动规划、控制执行，\textbf{闭环系统}：接收反馈信号重新抓取

\textbf{对已知物体的抓取条件}：预测物体位姿，RGB
图像需相机内参、物体大小（避免歧义 ambiguity）、
\textbf{无对称性}；点云只需 \textbf{无对称性}

\textbf{ICP}：初始化变换估计
\(T_0 = (R_0, t_0)\)，迭代（数据关联找变换后最近匹配点 + 变换求解
\(T_{k+1} = \arg \min_T \sum_{(m,s) \in C} \| Tm - s \|^2\)）直至收敛

\textbf{对未知物体的抓取方法}：直接预测抓取位姿，也有算法可以从见过同一类别物体进行泛化。

\textbf{旋转回归}：用神经网络估计连续的旋转变量，理想表达方式：表示空间到
\(\mathbb{SO}(3)\) 群一一映射、且满足连续性，即不存在
\textbf{奇点（Singularities）}

\textbf{欧拉角}、\textbf{轴角}：存在多义性。\textbf{四元数}：双重覆盖问题，约束空间为上半球则引入不连续性（临近球大圆的不连续性和球大圆上的不连续性）。\(q = \left[\cos\frac{\theta}{2}, \sin\frac{\theta}{2} \hat{\omega}\right]\)，本质是
\(\mathbb{R}^4\) 与 \(\mathbb{SO}(3)\) 无法构成拓扑同构, 至少
\(\mathbb{R}^5\) 才行

\textbf{6D 表示}：拟合旋转矩阵然后施密特正交化（Schmidt
orthogonalization），但拟合的 9 个数不等价

\textbf{9D 表示}：SVD 正交化，CNN
友好，连续、一一映射、等价。\(\hat{R} = U\begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & \det(UV) \end{bmatrix}V^{\top}\)（保证
\(\det(\hat{R}) = 1\)，符合手性不变性）

\textbf{增量旋转预测 Delta
Rotation}：小范围旋转，以上几种方式都适用，此时四元数等表示方法需要预测参数较少，学起来更快

\textbf{Rotation
Fitting}：通过神经网络预测拟合物体表面点的对应关系（相机坐标系
\((x_i^C, y_i^C, z_i^C)\) 到模型坐标系 \((x_i^M, y_i^M, z_i^M)\)
的最优变换矩阵）。步骤：对物体表面的每个像素，预测其在物体建模模型上的
3D 坐标；基于这些对应关系拟合旋转矩阵（要求物体见过）

\textbf{Orthogonal Procrustes}：给定两组点
\(\mathbf{M}, \mathbf{N} \in \mathbb{R}^{n \times 3}\)，求最优旋转矩阵
\(\mathbf{A}\) 使得
\(\hat{\mathbf{A}} = \arg\min_{\mathbf{A}} \|\mathbf{M} - \mathbf{N}\mathbf{A}^\top\|_F^2, \quad \text{s.t.}~\mathbf{A}^\top\mathbf{A} = \mathbf{I}\)，其中
\(\|X\|_F = \sqrt{\text{trace}(X^{\top}X)} = \sqrt{\sum_{i,j} x_{ij}^2}\)

解析解：对 \(\mathbf{M}^\top\mathbf{N}\) 做 SVD
分解，\(\mathbf{M}^\top\mathbf{N} = \mathbf{UDV}^\top\)，最优旋转为
\(\hat{\mathbf{A}} = \mathbf{U}\begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & \det(\mathbf{UV}^{\top}) \end{bmatrix}\mathbf{V}^{\top}\)，\(\hat{\mathbf{t}} = \overline{\mathbf{M}^{\top} - \hat{\mathbf{A}} \mathbf{N}^{\top}}\)

问题：对离群点敏感，常用 RANSAC 进行鲁棒拟合。

\textbf{RANSAC}：通过随机抽样找到内点 (inliers) 最多的模型假设，1.
以最小点集采样拟合所需模型（线=2，面=3，旋转=3）；2. 计算模型参数；3.
计算内点数量（距离小于阈值 \(\epsilon\) 的）；4.
迭代重复，找内点最多的模型。

\textbf{Instance Level Pose Estimation}：每个物体有独立模型，如
PoseCNN，结合 ICP 可提升精度

\textbf{Category Level Pose Estimation}：同类物体归一化到
\(1\times1\times1\) box，可预测旋转，预测平移需已知物体大小

\textbf{迭代最近点算法（ICP）}：作为后处理提高物体的位姿估计精度，提高抓取成功率；平移误差比旋转误差更敏感；怕物体被挡住造成
\textbf{点云缺失}。\textbf{目标}：优化初始位姿估计，对齐源点云
\(P = \{p_i\}\) 和目标点云 \(Q = \{q_j\}\) ；寻找最优旋转
\(\hat{R} \in\mathbb{SO}(3)\) 和平移
\(\hat{T}\in\mathbb{R}^{3\times 1}\)

流程：1. 中心化源、目标点集
\(\tilde{p}_i = p_i - \bar{P}, \tilde{q}_j = q_j - \bar{Q}\)；2.
\textbf{对应点匹配（Correspondence Search）}：为每个 \(\tilde{p}_i\)
找到最近邻 \(\tilde{q}_{j_i}\)；3. 求解位姿（解见前）；4. 用解变换源点集
\(P\)，然后迭代 2-3 直至收敛。

\textbf{ICP
收敛性}：\textbf{不保证全局收敛}，可能陷入局部最优。原因：\textbf{对应点匹配可能非一一映射}，两个源点映到同一目标点。\textbf{优点}：简单，无需特征提取，初始估计好时精度高。\textbf{缺点}：计算成本高（最近邻搜索），对初始位姿敏感，迭代慢，未充分利用结构信息。

\textbf{Category-Level Pose
Estimation}：解决实例级位姿估计需完整模型的问题，\textbf{通过归一化操作定义标准化物体空间
Normalized Object Coordinate Space（NOCS）}
，包括旋转对齐、平移归一、尺寸归一。

\textbf{ICP
算法需要很强的先验知识（物体的本身建模）}，然后进行变换前后点云配准，由于需要变换前后的\textbf{坐标对}，所以我们需要先进行\textbf{最近邻匹配}（也就是这一步导致了收敛性的缺失以及迭代速度的变慢），然后据此迭代得到物体位姿
\((R,t)\)

\textbf{NOCS 算法不需要完整的物体的本身建模}，而是通过标准化的 NOCS
空间隐式地引入了对于某一类物体的、相较于 ICP
算法\textbf{更粗粒度}的几何先验，降低了对于高精建模的依赖，使用\textbf{合成数据}训练得到一个神经网络，可以从
RGB 图像直接为每一个像素预测其在 NOCS 中的对应点 \((x,y,z)\)，随后将其与
RGBD
重建得到的点云信息进行配准，\textbf{这里根据像素关系，可以天然形成数量相同的变换前后的坐标对，所以不再需要找到最近邻（Correspondence）}。而后，我们可以直接用
Umeyama 算法（和 ICP 去除最近邻匹配的后半段类似）来重建得到 7 DoF
物体位姿 \((s,R,t)\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  输入 RGBD 图像，提取 RGB 信息，使用 Mask R-CNN 获得 ROI（Region of
  Interest），分割物体
\item
  预测每个像素的 NOCS 空间坐标 \((x,y,z)\)，得到 \textbf{NOCS Map}
\item
  将 NOCS Map 的点反投影（Back Projection）到三维空间中，得到点云数据
  \(\mathbf{q}_i\)
\item
  通过 NOCS Map 和 Depth 图像得到的点云数据，进行 Pose Fitting，利用
  Umeyama 算法，计算得出物体的 7DoF 位姿（缩放 + 旋转 +
  平移），缩放系数的计算就是简单的用 NOCS Map
  的各轴向长度与物体实际点云各轴向作了一个除法。而反过来计算 Bounding
  Box 的时候，则利用了 NOCS
  建模时令物体中心处在原点从而具有的对称性，以预测出的 NOCS Map
  各轴向最大绝对值乘 2 再乘缩放系数作为了 Bounding Box 的各轴向尺寸
\end{enumerate}

\textbf{额外引入 NCOS 而不是直接 NN 预测原始点然后结合 Depth 直接回归
6DoF 位姿的原因}：

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  实验效果优
\item
  将问题分解为 2D \(\to\) 3D 映射 + 3D \(\to\) 3D 几何优化，更直观
\item
  \textbf{NOCS 方法充分利用了形状 /
  几何先验}，提升了对未见物体的泛化能力。
\end{enumerate}

\textbf{Synthetic data 合成数据}：训练 NOCS
网络需要大量标注数据，但真实数据标注成本高、泛化性差，所以需要合成数据进行训练。然而存在
\textbf{Sim2Real Gap}，导致模型在真实世界性能下降

\textbf{Mixed Reality Data}
：将合成前景物体叠加到真实背景上，易于获取大量带 NOCS
标签的数据。问题：合成前景与背景 \textbf{分界太过明显}，从而导致分割的
Mask R-CNN 学习到的经验难以应用到真实世界

\textbf{Co-Training}
：结合图像分割领域收集的真实数据集与合成数据集来一同对 Mask R-CNN 进行
\textbf{混合训练}，但前者不参与后续的 NOCS
映射训练，\textbf{只为分割提供监督信号}

\textbf{后续处理}：对于预测得到的位姿，有时候还需要
Refinement，比如之前介绍的 ICP
算法，也可通过神经网络（合成数据训练）完成

\textbf{Form Closure}：纯几何约束，不依赖摩擦力，最稳固

\textbf{Force Closure}：依赖摩擦力，通过接触力抵抗任意 Wrench（力 +
力矩），也即可以让物体产生的任何加速度 \(a\) 和角加速度 \(\alpha\)

\(\text{Form Closure} \subseteq \text{Force Closure} \subseteq \text{Successful Grasp}\)，反例：1.
双指夹纸 2. 托起

\textbf{摩擦锥（Friction Cone）}：定义了在静摩擦系数 \(\mu\)
下，接触点不滑动的力的方向范围（与法线夹角最大值
\(\alpha = \arctan \mu\)）

\textbf{Force Closure 形式化}：定义抓取矩阵（Grasp
Matrix）\(F = \begin{bmatrix} \mathcal{F}_1 & \cdots & \mathcal{F}_j \end{bmatrix} \in \mathbb{R}^{n \times j},\ n = 3 \text{ or } 6,\ j = k \times C\)

其中，\(C\) 是接触点（摩擦锥）的数量，\(k\)
是为了近似每个摩擦锥所使用的力旋量数量（也即用多少面体锥来近似摩擦锥）。

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  抓取矩阵必须满秩： \(\text{rank}(F)=n\)
\item
  原点在凸锥内部（小正数下限保证稳定性）：\(Fk = 0 \text{ for some } k \in \mathbb{R}^j, k_i \ge \epsilon > 0 \text{ for all } i\)
\end{enumerate}

\textbf{GraspNet-1B}：获得物体模型 \(\to\) 在表面采样抓取位姿 \(\to\)
Force Closure 筛选 \(\to\) 场景生成与物体位姿标注 \(\to\)
变化抓取位姿到场景中，进行碰撞检测 \(\to\)
多视角渲染扩增数据集。\textbf{意义}：证明了基于 3D
几何的模型能有效学习抓取，但大规模多样性需要合成数据。

\textbf{摩擦系数 \(\mu\)}：GraspNet 数据集实际上为从低到高不同的 \(\mu\)
值都进行了筛选并存储了标签。\(\mu\) 值越低，对抓取的要求越高（更接近
Form Closure），这样的抓取在低摩擦表面上更可能成功。训练时可用小
\(\mu\)，泛化性强。

\textbf{Grasp Detection}：从输入（点云 / TSDF /
图像）预测抓取位姿，包括位置、朝向、夹爪宽度、质量分数。

\textbf{输入模态}：往往 3D 几何通常优于 2D
信息，\textbf{因其直接包含形状信息}。

\textbf{VGN（Volumetric Grasping Network）} 输入：3D
TSDF；架构：U-Net（3D
CNN）；输出：预测三个体素网格，即\textbf{对于输出网格中的每一个体素}，网络预测
\textbf{抓取质量（Grasp Quality/Score）} 、 \textbf{抓取朝向（Grasp
Orientation）} 、 \textbf{抓取宽度（Grasp Width）}
（防止夹爪过宽向外碰撞）

特点：\textbf{依赖几何信息}、不依赖纹理、Sim2Real 效果好（优势在于 TSDF
对传感器噪声不敏感；现实物理效应（力闭合、变形）可能优于仿真；可以工程优化摩擦系数问题），\textbf{Sim2Real
甚至可以是负的！}

评估指标：通常是与物体无关、非任务导向的 \textbf{抓取成功率（Success
Rate）} 、 \textbf{清理率（Percentage Cleard）} 、
\textbf{规划时间（Planning Time）}

后处理：\textbf{高斯平滑}（抓取评分非阶跃）、
\textbf{距离掩膜}（限制夹爪在 TSDF 的区域） 、 \textbf{基于质量的 NMS}

\textbf{VGN 的局限性}：依赖多视角构建完整的场景
TSDF、精度受体素大小限制、高分辨率计算所需的内存成本高

\textbf{GraspNet 成功的本质：}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  点云的优良性质：准确、轻量、效率高、精度高
\item
  架构：\textbf{端到端网络}，\textbf{多阶段设计}（先预测抓取分数，选高的做候选继续预测接近方向等），每个阶段都有监督信号，稳定
\item
  \textbf{泛化性}：局部性与平移等变性

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    \textbf{局部性}：Cylinder Grouping
    聚合，依赖候选点周围的局部几何信息判断，而不太关心场景中其他远处的物体。
  \item
    \textbf{平移等变性（Translation
    Equivariance）}：类似二维情形，模型学习到的几何模式识别能力不随物体在空间中的位置变化而失效。
  \end{enumerate}
\end{enumerate}

\textbf{Cylinder
Grouping}：在候选点附近，沿着接近方向定义一个圆柱体区域，聚合该区域内所有点的特征。这个聚合后的特征被用来预测最佳的旋转角和深度
/ 宽度。

GraspNet 的核心在于 \textbf{学习局部几何特征（Local Geometric
Features）与抓取成功的关系}，泛化性强

\textbf{抓取的条件生成模型}：替代检测方法，直接学习抓取位姿的分布（解决多峰分布）；尤其适用于高自由度灵巧手；常用条件扩散模型，基于局部几何特征生成抓取。

\textbf{DexGraspNet}：合成数据（Synthetic Data） + 深度学习

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  场景理解：预测每个点 \textbf{抓取可能性（Graspness）}，是否是
  \textbf{物体（Objectness）}
\item
  局部特征：不用全局特征（关联性弱、泛化性差），选择 Graspness
  高的地方附近的点云，提取局部特征（\textbf{几何信息}）
\item
  条件抓取生成模块：\textbf{条件生成处理 \((T, R)\)
  多峰分布}，然后采样后直接预测手指形态 \(\theta\)
\end{enumerate}

问题：仅处理包覆式抓取（Power Grasp），没处理指尖抓取（Precision
Grasp）；主要使用力封闭抓取；透明（Transparent）或高反光（Highly
Specular/Shiny）物体有折射（Refraction）/ 镜面反射（Specular
Reflection），导致点云质量差。

\textbf{ASGrasp}：深度修复，合成数据 +
监督学习。\textbf{域随机化}、多模态立体视觉、立体匹配（Stereo Matching）
。

\textbf{Affordance
可供性}：指一个物体所能支持或提供的交互方式或操作可能性，哪个区域、何种方式进行交互。

\textbf{Where2Act}：大量随机尝试 + 标注。学习从视觉输入预测交互点
\(a_p\)、交互方向 \(R_{z|p}\) 和成功置信度
\(s_{R|p}\)。\textbf{VAT-Mart}：预测一整条操作轨迹。

利用视觉输入进行预测：

\begin{itemize}
\tightlist
\item
  \textbf{物体位姿（Object Pose）}：需要模型、抓取标注。
\item
  \textbf{抓取位姿（Grasp
  Pose）}：直接预测抓取点和姿态，无模型或预定义抓取。
\item
  \textbf{可供性（Affordance）}
\end{itemize}

\textbf{启发式（Heuristic）规则}：预抓取
Pre-grasp，到附近安全位置再闭合，避免碰撞

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{操作复杂度有限}：难以处理复杂任务，受启发式规则设计限制。
\item
  \textbf{开环执行（Open-loop）}：规划一次，执行到底，闭眼做事。高频重复规划可近似闭环。
\end{enumerate}

\hypertarget{policy}{%
\section{Policy}\label{policy}}

\textbf{策略学习}：学习 \(\pi(a_t|s_t)\) 或 \(\pi(a_t|o_t)\)，实现
\textbf{闭环控制}。

\textbf{Behavior Cloning}：将 \(D = \{(s_i, a_i^*)\}\)
视为监督学习任务，学习 \(\pi_\theta(s) \approx a^*\)。

\textbf{Distribution shift}：策略 \(\pi_\theta\)
错误累积，访问训练数据中未见过的状态（\(p_\pi(s)\) 与
\(p_{\text{data}}(s)\) 不匹配），策略失效。

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{改变
  \(p_{\text{data}}(o_t)\)}：扩充专家数据的轨迹，使其能够覆盖策略执行过程中可能出现的状态空间。\textbf{主要是要学会纠偏}。DAgger；从（传统算法）最优解中获取；从教师策略中学习（有
  \textbf{Privileged Knowledge} ）
\item
  \textbf{改变 \(p_{\pi}(o_t)\)}：更好地去拟合专家路线，避免偏离。
\end{enumerate}

\textbf{Dataset Aggregation（DAgger）}：训练 \(\pi_i\) \(\Rightarrow\)
用 \(\pi_i\) \textbf{执行（Rollout）} 收集新状态 \(\Rightarrow\)
查询专家在此状态下的 \(a^*\) \(\Rightarrow\)
\(D \leftarrow D \cup \{(s, a^*)\}\) \(\Rightarrow\) 重新训练
\(\pi_{i+1}\)。\textbf{但是出错才标注，也会影响准确性。}

\textbf{遥操作数据（Teleoperation）}：贵，也存在泛化问题。

\textbf{非马尔可夫性}：引入历史信息，但可能过拟合，\textbf{因果混淆（Causal
Confusion）}。

\textbf{Multimodal behavior 多峰行为}：同时存在多个可行解；NN
直接回归会出现平均行为。处理：学习分布，而不是预测单一确定性动作，如
GMM、Diffusion、VAE、AR 等。

\textbf{Multi-task Learning}：不单独学习每一个任务；将目标也作为条件，即
\textbf{目标条件化（Goal-conditioned）}：\(\pi(a|s, g)\)，共享数据和知识。但
\(g\) 也有分布偏移问题。

\textbf{IL
局限性}：依赖专家数据、无法超越专家、不适用于需要精确反馈的高度动态 /
不稳定任务。

\textbf{Offline Learning}：固定数据集学习，无交互。\textbf{Online
Learning}：边交互边学习。

\textbf{策略梯度定理}：\(\nabla_\theta J(\theta) = \mathbb{E}_{\tau \sim p_\theta(\tau)} [\nabla_\theta \log p_\theta(\tau) R(\tau)]\)，\(\nabla_\theta J(\theta) \approx \frac{1}{N} \sum_{i=1}^{N} \nabla_\theta \log p_\theta(\tau^{(i)}) R(\tau^{(i)})\)，\(\nabla_\theta \log p_\theta(\tau) = \sum_{t=0}^{T-1} \nabla_\theta \log \pi_\theta(a_t | s_t)\)
，\textbf{奖励函数无需可导}。\emph{证明}：\(\nabla_\theta p_\theta(\tau) = p_\theta(\tau) \nabla_\theta \log p_\theta(\tau)\)，\(p_\theta(\tau) = p(s_0) \prod_{t=0}^{T-1} \pi_\theta(a_t | s_t) p(s_{t+1} | s_t, a_t)\)，取对数消无关。

\textbf{环境模型}：包括状态转移概率 \(p(s_{t+1} | s_t, a_t)\) 和奖励函数
\(r(s_t, a_t)\)

\begin{itemize}
\tightlist
\item
  \textbf{Model-Free}：不需要知道环境模型
\item
  \textbf{Model-Based}：利用神经网络学习环境模型
\end{itemize}

\textbf{REINFORCE}：\(\hat{g} = \frac{1}{N} \sum_{i=1}^{N} \left[ \left( \sum_{t=0}^{T-1} \nabla_\theta \log \pi_\theta(a_t^{(i)} | s_t^{(i)}) \right) R(\tau^{(i)}) \right]\)，按照整条轨迹的总回报
\(R(\tau^{(i)})\) 加权，\textbf{On-Policy}。BC
是平权。\textbf{优点}：\(\hat{g}\)
无偏。\textbf{缺点}：高方差（训练不稳定，收敛缓慢）、样本效率低（On-policy）。

如果想让 BC 足够好（避免 Distuibution Shift）：1.
正确覆盖所有的完美轨迹，且你训练的模型能够正确地 follow 这些轨迹；2.
对各种 error 的 corner case 都有拽回来的部分覆盖，但不要有导致 error
发生的部分

\textbf{On-Policy}：数据来自\textbf{当前策略}。效果好，\textbf{样本效率低}，每次都得重新采样。\textbf{Off-Policy}：数据\textbf{可来自不同策略}。\textbf{样本效率高}，可能不稳定。

\textbf{Reward-to-Go}：降方差，用未来回报
\(\hat{Q}(s_t, a_t) = \sum_{t'=t}^{T} r_{t'}\)
加权梯度。认为\textbf{一个动作只对未来的奖励负责}。

\textbf{Baseline}：降方差，减去 \(a_t\) 无关状态基线
\(b(s_t)\)，\(\hat{Q}(s_t, a_t) - b(s_t)\)
加权。梯度无偏。\emph{证明}：\(\mathbb{E}[\nabla_\theta \log p_\theta(\tau) b] = \int p_\theta(\tau) \nabla_\theta \log p_\theta(\tau) b \, \mathrm{d}\tau = \int \nabla_\theta p_\theta(\tau) b \, \mathrm{d}\tau = b \nabla_\theta \int p_\theta(\tau) \, \mathrm{d}\tau = b \nabla_\theta 1 = 0\)

\textbf{最优基线}：\(b^* = \frac{\mathbb{E}[(\nabla_\theta \log p_\theta(\tau))^2 R(\tau)]}{\mathbb{E}[(\nabla_\theta \log p_\theta(\tau))^2]}\)，\emph{证明}：令
\(g(\tau, b) = \nabla_\theta \log p_\theta(\tau) (R(\tau) - b)\)，\(\mathrm{Var}[g(\tau, b)] = \mathbb{E}[g(\tau, b)^2] - (\mathbb{E}[g(\tau, b)])^2\)，\(\mathbb{E}[g(\tau, b)^2] = \mathbb{E}[(\nabla_\theta \log p_\theta(\tau))^2 (R(\tau) - b)^2]\)，两边对
\(b\) 求导令其等于 0。

\textbf{均值基线}：\(b = \frac{1}{N} \sum_{i=1}^N R(\tau^{(i)})\)，使用蒙特卡洛算法，不同的
\(b\) 的选择的确会影响采样计算出的 \(\nabla_\theta J(\theta)\)
近似值，但是这是由于采样不足，\(N\) 不够大造成的。

\textbf{状态价值函数}
\(V^{\pi_\theta}(s_t) = \mathbb{E}_{\tau \sim p_\theta(\tau)} \left[ \sum_{t'=t}^{T} \gamma^{t'-t} r_{t'} \middle| s_t \right] = \mathbb{E}_{a_t \sim \pi_\theta(\cdot|s_t)} [Q^{\pi_\theta}(s_t, a_t)]\)：表示从状态
\(s_t\) 开始，遵循策略 \(\pi_\theta\)
之后所能获得的期望（折扣）Reward-to-Go 回报，它只依赖于状态 \(s_t\)
和策略 \(\pi_\theta\)。

\textbf{动作价值函数}
\(Q^{\pi_\theta}(s_t, a_t) = \mathbb{E}_{\tau \sim p_\theta(\tau)} \left[ \sum_{t'=t}^{T} \gamma^{t'-t} r_{t'} \middle| s_t, a_t \right] = r(s_t, a_t) + \gamma \mathbb{E}_{s_{t+1} \sim P(\cdot|s_t, a_t)} [V^{\pi_\theta}(s_{t+1})]\)：表示在状态
\(s_t\) 采取动作 \(a_t\) 后，再遵循策略 \(\pi_\theta\)
所能获得的期望（折扣）Reward-to-Go 回报，它依赖于状态 \(s_t\)、动作
\(a_t\) 和策略 \(\pi_\theta\)。

\textbf{Advantage
基线}：\(A^{\pi_\theta}(s_t, a_t) = Q^{\pi_\theta}(s_t, a_t) - V^{\pi_\theta}(s_t) = r(s_t, a_t) + \gamma \mathbb{E}_{s_{t+1} \sim P(\cdot|s_t, a_t)} [V^{\pi_\theta}(s_{t+1})] - V^{\pi_\theta}(s_t)\)，动作相对平均的优势，可替换\(R(\tau^{(i)})\)
做权值，即
\(\nabla_\theta J(\theta) = \mathbb{E}_{(s_t, a_t) \sim \pi_\theta} [ \nabla_\theta \log \pi_\theta(a_t | s_t) A^{\pi_\theta}(s_t, a_t) ]\)。估计值：\(\hat{A}(s_t, a_t) = r(s_t, a_t) + \gamma \hat{V}(s_{t+1}) - \hat{V}(s_t)\)（暴力地对期望
\(\mathbb{E}_{s_{t+1} \sim P(\cdot|s_t, a_t)} [V^{\pi_\theta}(s_{t+1})]\)
进行蒙特卡洛估计）

\textbf{估计 \(V(s_t)\)} ：1.
\textbf{蒙特卡洛}，\(\hat{V}(s_t) = \frac{1}{N} \sum_{i=1}^{N} \sum_{t'=t}^{T} \gamma^{t' - t} r(s_{t'}, a_{t'})\)；2.
\textbf{神经网络（监督学习）}：\(\hat{V}(s) = \hat{V}_{\phi}(s)\)，\(\mathcal{D} = \{ (s_{i,t}, r(s_{i,t}, a_{i,t}) + \gamma \hat{V}_{\phi}^{\pi}(s_{i,t+1}) \}\)，其中，\(s_{i,t}\)
是在第 \(i\) 条轨迹、时刻 \(t\) 遇到的状态。

\textbf{Bootstrap 自举}：使用基于当前函数估计的值
\(\hat{V}_{\phi}^{\pi}(s_{i,t+1})\) 来更新 \textbf{同一个函数}
在另一个点 \(s_{i,t}\) 的估计 \(\hat{V}_{\phi}^{\pi}(s_{i,t})\)

\textbf{Actor-Critic}：还是
\(\nabla_\theta J(\theta) = \mathbb{E}_{(s_t, a_t) \sim \pi_\theta} [ \nabla_\theta \log \pi_\theta(a_t | s_t) A^{\pi_\theta}(s_t, a_t) ]\)

\begin{itemize}
\tightlist
\item
  \textbf{Actor（演员）}：指策略网络
  \(\pi_\theta(a_t|s_t)\)，负责根据状态 \(s_t\) 做出动作决策，决定此步的
  \(r(s_t, a_t)\) 进而影响 \(A(s_t, a_t)\)
\item
  \textbf{Critic（评论家）}：指价值网络（\(V_{\phi}(s_t)\) 或者
  \(Q_{\phi}(s_t, a_t)\)，\(\phi\) 表示其参数），负责评估 Actor
  所处的状态 \(s_t\) 或采取的动作 \(a_t\) 的好坏（即估计 \(V\) 值或
  \(Q\) 值，进而计算优势 \(A\) 值）
\end{itemize}

在训练完成后，真正推理（干活）的时候，不用 Critic，只用 Actor。

\textbf{Batch AC}：收集一批完整轨迹或转换数据后，统一更新 C /
A。梯度估计更稳定，但更新频率低。

\textbf{Online AC}：每一步交互（\textbf{或极小批量}）后，立即更新 C /
A。更新快，数据利用率高，但梯度估计方差较大。

A / C
可共享网络的底层部分，增加参数效率，但训练可能更复杂，且一般效率劣于分开时。

即使在 Online AC 中，也常常收集一个小批量数据来更新 Critic
\(\hat{V}_\phi^\pi\) 和 Actor
\(\theta\)，因为这有助于稳定学习过程，降低梯度估计的方差。

\textbf{Parallelization}：多 worker
采样，提速增稳。并行又可分为\textbf{同步（Synchronous）}和\textbf{异步（Asynchronous）}。同步并行存在同步点，整体速度受限于最慢的
worker。异步并行则没有同步点，会更快。

\end{multicols*}

\end{document}
